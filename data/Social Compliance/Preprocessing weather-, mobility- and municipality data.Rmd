---
title: "Pre Processing COVID-19 Analysis Data"
author: "Lasse Hyldig Hansen"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This vignette demonstrates how I have preprocessed redily information used for understanding how weather, mobility and municipality demographics impact the spread of COVID-19 in Danish Municipalities.

First I will start by loading the packages that will be necessarry to do both data preprocessing and analysis,

To preprocess the weather data from DMI, I have created a function that can turn the data from their API into something useful. This module will therefore also be loaded in the chunk below.

Remove ## Before Running this step if you do not have the packages below.

```{r}

#Installing the required packages from github:
  
#install.packages("devtools")

#devtools::install_github("klmr/modules", force = T) # for loading the functions i made for loading DMI data including their documentation

#install.packages("pacman")

pacman::p_load(tidyverse, 
               purrr, 
               tidyr, 
               stringr, 
               Boruta, 
               ggplot2,
               sandwich,
               survival,
               car,
               ggpubr,
               pracma,
               effects
               )
CM <- modules::import("COVID_MODEL_helpfuns", attach = T, doc = T) #Loading my own DMI module

modules::reload(CM) # this simply reloads the module in case of any changes

```

#### Loading DMI Weather Variables

You need to have loaded data from https://dmigw.govcloud.dk/metObs/v1/bulk/?api-key=e32551a3-e242-45ae-8480-6129201f9a4c and put them in a folder which you need to refer to in the code chunk below.

Remove ## Before Running this step if want to run the preprocessing yourself.

```{r Using function}
#data <- list.files(path = "Your Path / Your Folder", pattern = ".txt") %>% # Change this to your own folder names
#    purrr::map_df(PreProc) #Using the module to load all DMI files (1 for each month) at a time

#write.csv(data, "DMI_DATA_CLEAN_project.csv")

```

The dmi weather variables are now saved in the file called 'DMI_DATA_CLEAN.csv'. Which is also readily avaliable in the github folder.

So, if you do not want to download the data yourself and use my function, I have made file above avaliable. I will start by loading this for you:

```{r}
data <- read_csv("DMI_DATA_CLEAN.csv")
data$X1 <- NULL
```

However, notice that there is a problem, since every municipality with every date are not represented.

This is going to seem very cumbersome, but to make sure that each municipality has a date I am going to make a copy for each of them. Afterwards i bind them all and make two copies of the DMI_DATA_ClEAN. One called data9 and one called data10:

```{r Adding municipalities without weather data, message=FALSE, warning=FALSE}
sub <- subset(data, Kommune == "Tønder")
sub[, 2:7] <- "NA"
sub$Kommune <- "Kolding"
sub$Kolonne1 <- "10"

sub1 <- sub
sub1$Kommune <- "Ærø"
sub1$Kolonne1 <- "14"

sub2 <- sub1
sub2$Kommune <- "Albertslund"
sub2$Kolonne1 <- "19"

sub3 <- sub1
sub3$Kommune <- "Allerød"
sub3$Kolonne1 <- "19"

sub4 <- sub1
sub4$Kommune <- "Ballerup"
sub4$Kolonne1 <- "19"

sub5 <- sub1
sub5$Kommune <- "Brøndby"
sub5$Kolonne1 <- "19"

sub41 <- sub1
sub41$Kommune <- "Brønderslev"
sub41$Kolonne1 <- "1"

sub42 <- sub1
sub42$Kommune <- "Christiansø"
sub42$Kolonne1 <- "14"

sub44 <- sub1
sub44$Kommune <- "DMI"
sub44$Kolonne1 <- "19"


sub6 <- sub1
sub6$Kommune <- "Dragør"
sub6$Kolonne1 <- "19"

sub7 <- sub1
sub7$Kommune <- "Egedal"
sub7$Kolonne1 <- "19"

sub8 <- sub1
sub8$Kommune <- "Frederiksberg"
sub8$Kolonne1 <- "19"

sub9 <- sub1
sub9$Kommune <- "Frederikssund"
sub9$Kolonne1 <- "18"

sub10 <- sub1
sub10$Kommune <- "Gladsaxe"
sub10$Kolonne1 <- "19"

sub11 <- sub1
sub11$Kommune <- "Glostrup"
sub11$Kolonne1 <- "19"

sub12 <- sub1
sub12$Kommune <- "Halsnæs"
sub12$Kolonne1 <- "18"


sub13 <- sub1
sub13$Kommune <- "Herlev"
sub13$Kolonne1 <- "19"


sub14 <- sub1
sub14$Kommune <- "Helsingør"
sub14$Kolonne1 <- "19"


sub15 <- sub1
sub15$Kommune <- "Hørsholm"
sub15$Kolonne1 <- "19"


sub16 <- sub1
sub16$Kommune <- "Hvidovre"
sub16$Kolonne1 <- "19"


sub17 <- sub1
sub17$Kommune <- "Ishøj"
sub17$Kolonne1 <- "19"


sub18 <- sub1
sub18$Kommune <- "Jammerbugt"
sub18$Kolonne1 <- "2"

sub19 <- sub1
sub19$Kommune <- "Lejre"
sub19$Kolonne1 <- "18"


sub20 <- sub1
sub20$Kommune <- "Lemvig"
sub20$Kolonne1 <- "4"

sub21 <- sub1
sub21$Kommune <- "Lyngby-Taarbæk"
sub21$Kolonne1 <- "19"

sub22 <- sub1
sub22$Kommune <- "Rebild"
sub22$Kolonne1 <- "2"

sub23 <- sub1
sub23$Kommune <- "Rødovre"
sub23$Kolonne1 <- "19"

sub24 <- sub1
sub24$Kommune <- "Roskilde"
sub24$Kolonne1 <- "17"

sub25 <- sub1
sub25$Kommune <- "Rudersdal"
sub25$Kolonne1 <- "19"

sub26 <- sub1
sub26$Kommune <- "Solrød"
sub26$Kolonne1 <- "17"

sub27 <- sub1
sub27$Kommune <- "Sorø"
sub27$Kolonne1 <- "16"

sub28 <- sub1
sub28$Kommune <- "Stevns"
sub28$Kolonne1 <- "17"

sub29 <- sub1
sub29$Kommune <- "Vallensbæk"
sub29$Kolonne1 <- "19"

sub100 <- sub1
sub100$Kommune <- "Vejle"
sub100$Kolonne1 <- "11"

sub101 <- sub1
sub101$Kommune <- "Billund"
sub101$Kolonne1 <- "7"

sub45 <- sub1
sub45$Kommune <- "Greve"
sub45$Kolonne1 <- "17"

sub46 <- sub1
sub46$Kommune <- "Fredensborg"
sub46$Kolonne1 <- "19"

sub47 <- sub1
sub47$Kommune <- "Hillerød"
sub47$Kolonne1 <- "19"

sub48 <- sub1
sub48$Kommune <- "Høje-Taastrup"
sub48$Kolonne1 <- "19"

sub49 <- sub1
sub49$Kommune <- "Odense"
sub49$Kolonne1 <- "12"

sub50 <- sub1
sub50$Kommune <- "Langeland"
sub50$Kolonne1 <- "14"

sub51 <- sub1
sub51$Kommune <- "Faxe"
sub51$Kolonne1 <- "17"

sub52 <- sub1
sub52$Kommune <- "Ringsted"
sub52$Kolonne1 <- "18"

sub53 <- sub1
sub53$Kommune <- "Kerteminde"
sub53$Kolonne1 <- "12"

sub54 <- sub1
sub54$Kommune <- "Morsø"
sub54$Kolonne1 <- "12"

sub55 <- sub1
sub55$Kommune <- "Odder"
sub55$Kolonne1 <- "11"

sub56 <- sub1
sub56$Kommune <- "Vejen"
sub56$Kolonne1 <- "9"

sub57 <- sub1
sub57$Kommune <- "Mariagerfjord"
sub57$Kolonne1 <- "2"

sub58 <- sub1
sub58$Kommune <- "Struer"
sub58$Kolonne1 <- "4"

sub59 <- sub1
sub59$Kommune <- "Fredensborg"
sub59$Kolonne1 <- "19"

sub60 <- sub1
sub60$Kommune <- "Gribskov"
sub60$Kolonne1 <- "19"



bind <- rbind(sub, sub1, sub2, sub3, sub4, sub5, sub6, sub7, sub8, sub9, sub10, sub11, sub12, sub13, sub14, sub15, sub16, sub17, sub18, sub19, sub20, sub21, sub22, sub23, sub24, sub25, sub26, sub27, sub28, sub29, sub41, sub42, sub44, sub45, sub46, sub47, sub48, sub49, sub50, sub51, sub52, sub53, sub54, sub55, sub56, sub57, sub58, sub100, sub101, sub59, sub60)
kommune  <- read.csv("Kommuneposition (1).csv", sep = ";") #Loading in file about danish municipalities

bind$stationID <- as.numeric(bind$stationID)
bind$humidity_past1h <-  as.numeric(bind$humidity_past1h)
bind$precip_dur_past1h <-  as.numeric(bind$precip_dur_past1h)
bind$sun_last1h_glob <-  as.numeric(bind$sun_last1h_glob)
bind$temp_mean_past1h <-  as.numeric(bind$temp_mean_past1h)
bind$wind_speed_past1h <-  as.numeric(bind$wind_speed_past1h)

data111 <- left_join(data, kommune)
data111$Kommune_Nummer <- NULL
bind$Date <- as.Date(bind$Date)
bind$Kolonne1 <- as.integer(bind$Kolonne1)
data111$Date <- as.Date(data111$Date)
data10 <- rbind(bind, data111)
data10$Kommune = ifelse(data10$Kommune == "6052", "Lemvig", data10$Kommune)
data9 <- data10 %>% select(Date, Kommune)
```


#### Loading Google Mobility Data - Cleaning it to match Municipality names

First I will start by loading 2020_DK_Region_Mobility_Report1.csv from the folder. Afterwards, I do some basic preprocessing. The primary object of this is to be able to match every municipality on every date, so that we can take advantage of the panel-data structure in the dataset later (Because we have used a mixed effects model).



```{r Loading 2020 mobility data from google, message=FALSE}
mobility <- read_csv("2020_DK_Region_Mobility_Report1.csv")

mobility$CountDate <- as.numeric(mobility$date)

mobility$sub_region_2 <- gsub(" Municipality", "", mobility$sub_region_2)
mobility$sub_region_2 <- gsub(" ", "", mobility$sub_region_2)

mobility_region = mobility %>% filter(is.na(.$sub_region_2)) %>% filter(!is.na(.$sub_region_1)) %>% select(sub_region_1, date, 10:16)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Vesthimmerland", "Vesthimmerlands", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Brondby", "Brøndby", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Copenhagen", "København", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Nordfyn", "Nordfyns", mobility$sub_region_2)

mobility = mobility %>% filter(!is.na(sub_region_2))

mobility <- mobility %>% select(date, sub_region_1, sub_region_2, residential_percent_change_from_baseline, workplaces_percent_change_from_baseline, transit_stations_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, parks_percent_change_from_baseline, grocery_and_pharmacy_percent_change_from_baseline)

colnames(mobility) <- c("Date", "Region", "Kommune", "Residential", "Workplace", "Transit", "Retail", "Park", "Grocery")
```

Afterwards I do the same for the 2021 data, and then i bind the data together.

```{r Loading 2021 mobility data from google, message=FALSE, warning=FALSE}
mobility1 <- read_csv("2021_DK_Region_Mobility_Report.csv") 

mobility1$CountDate <- as.numeric(mobility1$date)

mobility1$sub_region_2 <- gsub(" Municipality", "", mobility1$sub_region_2)
mobility1$sub_region_2 <- gsub(" ", "", mobility1$sub_region_2)

mobility_region2020 = mobility1 %>% filter(is.na(.$sub_region_2)) %>% filter(!is.na(.$sub_region_1)) %>% select(sub_region_1, date, 10:16)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Vesthimmerland", "Vesthimmerlands", mobility1$sub_region_2)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Brondby", "Brøndby", mobility1$sub_region_2)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Copenhagen", "København", mobility1$sub_region_2)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Nordfyn", "Nordfyns", mobility1$sub_region_2)

mobility1 = mobility1 %>% filter(!is.na(sub_region_2))


mobility1 <- mobility1 %>% select(date, sub_region_1, sub_region_2, residential_percent_change_from_baseline, workplaces_percent_change_from_baseline, transit_stations_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, parks_percent_change_from_baseline, grocery_and_pharmacy_percent_change_from_baseline)

colnames(mobility1) <- c("Date", "Region", "Kommune", "Residential", "Workplace", "Transit", "Retail", "Park", "Grocery")

mobility2 <- rbind(mobility, mobility1)
mobility20 <- rbind(mobility_region, mobility_region2020)
mobility11 <- left_join(data9, mobility2, by = c("Kommune", "Date"))
mobility20 = mobility20 %>% rename(Date = date)
mobility20 = mobility20 %>% rename(Region = sub_region_1)
```

It is now necessary to use the Region Identifier function from my own module to replace data if necessary. Look in the documentation for further info on what the function does.

```{r}
mobility11 <- CM$Region_identifier(mobility11)
```

If municipality does not contain data for a date, replace with region mean for the day

```{r Making sure every region has every date}

join = left_join(mobility11, mobility20, by = c("Region", "Date"))

join$Residential = ifelse(is.na(join$Residential), join$residential_percent_change_from_baseline, join$Residential)

join$Transit = ifelse(is.na(join$Transit), join$transit_stations_percent_change_from_baseline, join$Transit)

join$Retail = ifelse(is.na(join$Retail), join$retail_and_recreation_percent_change_from_baseline, join$Retail)

join$Workplace = ifelse(is.na(join$Workplace), join$workplaces_percent_change_from_baseline, join$Workplace)

mobility_dat = join %>% subset(.$Kommune != "Christiansø")
mobility_dat = mobility_dat %>% subset(.$Kommune != "DMI")
mobility_dat = mobility_dat %>% select(Date, Kommune, Region, Transit, Residential, Retail, Workplace)

mobility_dat = mobility_dat %>% group_by(Date, Kommune) %>% 
  summarise(
    Transit = mean(Transit),
    Residential = mean(Residential),
    Retail = mean(Retail),
    Workplace = mean(Workplace)
  )
  
  
write_csv(mobility_dat, "mobility_dat.csv") #Data is saved as 'mobility_dat.csv' for your use
```

Then I go onto merge mobility data and weather data for each municipality on each date. We are now opting to reach a panel-structure in the end.

```{r Taking mean of weather variables per weather station in municipalities, message=FALSE}
kommune  <- read.csv("Kommuneposition (1).csv", sep = ";") #Loading in file about danish municipalities
data1 <- full_join(data10, kommune, by = "Kommune", "Date")

data1$Kolonne1 <- ifelse(is.na(data1$Kolonne1.x), data1$Kolonne1.y, data1$Kolonne1.x)
data1$Kolonne1.y <- NULL
data1$Kolonne1.x <- NULL

data1 <- filter(data1, Kommune != "DMI") # Filtering out two datapoints that we do not need for analysis
data1 <- filter(data1, Kommune != "Christiansø")
data4 <- data1 %>% 
  select(Date, Kommune, humidity_past1h, precip_dur_past1h, sun_last1h_glob, temp_mean_past1h, Kolonne1, wind_speed_past1h) %>% 
  group_by(Kolonne1, Date) %>% 
  summarise(
    Humid = mean(humidity_past1h, na.rm = T),
    Precip = mean(precip_dur_past1h, na.rm = T),
    Sun = mean(sun_last1h_glob, na.rm = T),
    Temp = mean(temp_mean_past1h, na.rm = T),
    Wind = mean(wind_speed_past1h, na.rm = T),
    Kommune = Kommune
            )

data4 <- data4 %>% 
  group_by(Date, Kommune) %>% 
  summarise(
    Humid = mean(Humid, na.rm = T),
    Precip = mean(Precip, na.rm = T),
    Sun = mean(Sun, na.rm = T),
    Temp = mean(Temp, na.rm = T),
    Wind = mean(Wind, na.rm = T),
            )

data4$Date <- as.Date(data4$Date)
data4 <- left_join(mobility_dat, data4, by = c("Kommune" = "Kommune", "Date" = "Date"))

data4 <- filter(data4, Kommune != "DMI")
```


Afterwards, we needed the daily cases of COVID-19 from SSI, this is therefore loaded in a time-series format.

For this you will need the file: Municipality_cases_time_series.csv, which was obtained from the danish health departments website.

```{r message=FALSE}

positive <- read.csv("Municipality_cases_time_series.csv", sep = ";")
positive$NA. <- NULL

positive <- positive[complete.cases(positive), ]
positive <- positive %>% pivot_longer(., 2:99)
colnames(positive) <- c("Date", "Kommune", "Cases")

positive$Kommune <- ifelse(positive$Kommune == "Copenhagen", "København",
                  ifelse(positive$Kommune == "Høje.Taastrup", "Høje-Taastrup",
                  ifelse(positive$Kommune == "Lyngby.Taarbæk", "Lyngby-Taarbæk",
                  ifelse(positive$Kommune == "Faaborg.Midtfyn", "Faaborg-Midtfyn",
                  ifelse(positive$Kommune == "Ikast.Brande", "Ikast-Brande",
                  ifelse(positive$Kommune == "Ringkøbing.Skjern", "Ringkøbing-Skjern",
                  ifelse(positive$Kommune == "Copenhagen", "København", positive$Kommune
                         )))))))

positive <- filter(positive, Kommune != "DMI")


positive$Date <- as.Date(positive$Date)

data5 <- left_join(data4, positive)
```

To take into consideration the stringency of the government throughout the period of the pandemic in Denmark, we used the Oxford Stringency Index.

This is loaded and the version we have used is in the file: covid-stringency-index (1).csv.

Additional information about the measure is given here: https://www.bsg.ox.ac.uk/research/research-projects/covid-19-government-response-tracker.

```{r Reading in stringency index, message=FALSE}
string <- read_csv("covid-stringency-index (1).csv")
string = string %>% filter(., Entity == "Denmark")
string$Date <- as.Date(string$Day)
string$Entity <- NULL
string$Code <- NULL
```

#### Moving onto loading data from Statistics Denmark

To do this we will need the package from the github repository dkstat. This is loaded the following way:

```{r Getting devtools for dkstat, message=FALSE}
if(!require("devtools")) install.packages("devtools")

library("devtools")

install_github("rOpenGov/dkstat", force =TRUE )

library(dkstat)

table<- dst_get_tables(lang = "da") #This is a table of all Statistics Denmark data.
aulaar_meta <- dst_meta(table = "AREALDK", lang = "da") #We will use the table "AREALDK"
```

Then I will load information about builded areas in denmark and put them into a dataframe called "Befolk"

```{r}
Befolk <- dst_get_data(table = "AREALDK", ARE1 = "Bygninger og bebyggede områder" , ENHED = "Kvadratmeter (m2) pr. indbygger",  OMRÅDE = "*", Tid = "2018")
Befolk$Kommune = Befolk$OMRÅDE
Befolk$Bebyggelse = Befolk$value
Befolk = Befolk %>% select(Kommune, Bebyggelse)
```

Afterwards i load the Number of Young Adults in each municipality and make them into percentages:

```{r Getting age characteristics}
city <- dst_get_data(table = "BY2" , KOMK = "*", ALDER = "*", KØN = "*", Tid = "2020")
city$ALDER <- gsub("år", "", city$ALDER)

colnames(city) <- c("Kommune", "Alder", "Køn", "Date", "Antal_Gruppe")

city$Alder <- as.numeric(city$Alder)

city <- subset(city, Alder <= 100)

city <- subset(city, Kommune != "Christiansø")

city1 <- city %>% 
     mutate(Alder = ifelse(Alder >= 19 & Alder < 30, "Under_30",
                      ifelse(Alder >= 30 & Alder < 110, "Over_30", "h"))) %>% 
     group_by(Kommune, Alder) %>% 
     summarise(
       Antal = sum(Antal_Gruppe)
     )       
                           

city <- city1 %>% group_by(Kommune, Alder) %>% 
     pivot_wider(., 1:3, names_from = Alder, values_from = Antal) 

city <- city %>% mutate(
       Total = Under_30 + Over_30 + h,
       Under_30 = (Under_30/Total)*100,
       Over_30 = (Over_30/Total)*100)
```

Then i load the Population Number of each municipality.

For this, the csv file BY3.csv from the repository will be needed.

```{r}
BY3 <- read_csv("BY3.csv") #Avaliable in materials
```

Because we consider how lagged weather and mobility data affects the present cases of COVID-19 i am Making lagged variables for analysis with the function lag():

```{r}
data7 <- data5 %>% group_by(Kommune) %>% mutate(
  Humid_lag = lag(Humid, 9),
  Temp_lag = lag(Temp, 9),
  Precip_lag = lag(Precip, 9),
  Cases_lag9 = lag(Cases, 9),
  Retail_Change_lag = lag(Retail, 9),
  Transit_Change_lag = lag(Transit, 9), 
  Residential_Change_lag = lag(Residential, 9),
  Workplace_Change_lag = lag(Workplace, 9)
  )
```

Then, I will join all the dataframes made previously in the document, to have the full-panel data structure with all variables.

```{r Joining it all for the analysis}

join1 <- full_join(BY3, city, by = c("Kommune"))
join2 <- left_join(join1, Befolk, by = "Kommune")
d7 <- left_join(data7, string, by = "Date")
d8 <- full_join(d7, join2, by = c("Kommune"))
d7 = d8
d8$Week <- strftime(d8$Date, format = "%Y-W%V")
d8$CountDate <- as.Date(d8$Date, format= "%Y-%m-%d")
d8 = d8 %>% subset(Kommune != "Christiansø")

```

Lastly, I make the stringency index lagged variables. Take rolling averages from mobility, weather and COVID-19 cases data. Further, I filter only the dates relevant for our analysis, and scale the data.

```{r}
d9 = d8 %>% ungroup() %>% mutate(
  Stringency = lag(stringency_index, 9),
  Cases = ((100000/Befolkningstal)*Cases),
  Cases_lag9 = ((100000/Befolkningstal)*Cases_lag9),
  Cases_lag9 = movavg(Cases_lag9, n = 7, type = "s"),
  Precip_lag= movavg(Precip_lag, n = 7, type = "s"),
  Temp_lag= movavg(Temp_lag, n = 7, type = "s"),
  Humid_lag= movavg(Humid_lag, n = 7, type = "s"),
  Transit_Change_lag= movavg(Transit_Change_lag, n = 7, type = "s"),
  Work_Change_lag= movavg(Workplace_Change_lag, n = 7, type = "s"),
  Retail_Change_lag= movavg(Retail_Change_lag, n = 7, type = "s"),
  Residential_Change_lag= movavg(Residential_Change_lag, n = 7, type = "s"),
  Cases = movavg(Cases, n = 7, type = "s"),
) %>% select(Cases_lag9 , Stringency, Bebyggelse, Over_30 , Transit_Change_lag , Residential_Change_lag, Kommune, Date, Week, Under_30, Cases, Temp_lag, Precip_lag, Work_Change_lag, Retail_Change_lag, Befolkningstæthed)

d9 = d9 %>%  subset(.$Date >= "2020-09-01" & .$Date <= "2021-02-28") #Subsetting the dates needed for analysis

d9$Stringency = scale(d9$Stringency)
d9$Cases_lag9 = scale(d9$Cases_lag9)
d9$Precip_lag = scale(d9$Precip_lag)
d9$Temp_lag = scale(d9$Temp_lag)
d9$Transit_Change_lag = scale(d9$Transit_Change_lag)
d9$Work_Change_lag = scale(d9$Work_Change_lag)
d9$Retail_Change_lag = scale(d9$Retail_Change_lag)
d9$Residential_Change_lag = scale(d9$Residential_Change_lag)
d9$Under_30 = scale(d9$Under_30)
d9$Befolkningstæthed = scale(d9$Befolkningstæthed)
d9$Bebyggelse = scale(d9$Bebyggelse)

d10 = d9 %>% drop_na() #dropping na's

mean(d9$Stringency) #testing that scaling works

write_csv(d10, "data_for_analysis.csv")
```

Now we have the file data_for_analysis.csv, which is the data-file that I will use in the data-analysis and  plotting markdown.
